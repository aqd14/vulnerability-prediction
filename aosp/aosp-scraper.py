"""
Scrape Firefox vulnerability list for each version

each vulnerability contains:
+ title
+ reporter
+ impact
+ description
+ bug id and href

"""

import requests
from bs4 import BeautifulSoup
import re
import pandas as pd


def extract_vulnerabilities(version, url):
    """
    Extract vulnerability reported for a Firefox version

    :param version: Firefox version to be scraped
    :param url: firefox vulnerability link for specific version
    :return: a DataFrame containing all vulnerability information for the given Firefox version
    """

    cve_ids = []
    titles = []
    reporters = []
    impacts = []
    descriptions = []
    bug_ids = []

    r = requests.get(url)
    soup = BeautifulSoup(r.content, 'lxml')
    vulnerabilities = soup.find_all(class_='cve')

    for item in vulnerabilities:

        # extract heading
        head = item.find(class_='level-heading')
        cve_id = head['id']
        title = head.find('a').text.replace(cve_id + ': ', '').replace('#', '')  # remove unnecessary part in title

        # extract summary
        summary = item.find(class_='summary')
        reporter = summary.find('dd').text
        impact = summary.find(class_=re.compile('^level')).text
        description = summary.find_next_sibling('p').text
        bug_id = item.find('ul').find('a').text.replace('Bug ', '')

        # add extracted information to list
        cve_ids.append(cve_id)
        titles.append(title)
        reporters.append(reporter)
        impacts.append(impact)
        descriptions.append(description)
        bug_ids.append(bug_id)

    df = pd.DataFrame({
        'version': [version] * len(vulnerabilities),
        'cve_id': cve_ids,
        'title': titles,
        'reporter': reporters,
        'impact': impacts,
        'description': descriptions,
        'bug_id': bug_ids,
    })
    return df


def scrape():
    firefox_vul_url = 'https://www.mozilla.org/en-US/security/known-vulnerabilities/firefox/'

    r = requests.get(firefox_vul_url)

    if r.status_code != 200:
        print('Can\'t retrieve the url %s' % firefox_vul_url)
        exit(1)

    soup = BeautifulSoup(r.content, 'lxml')

    versions = soup.find_all('h3', id=re.compile('^firefox'))

    print(len(versions))

    dfs = []
    for v in versions:
        item = v.find_next_sibling('ul')
        class_item = item.find('a')#.find('a').href
        link = 'https://www.mozilla.org' + class_item['href']
        print(link)
        fixed_version = class_item['data'].replace('version', '').replace('"', '').replace('=', '')
        print(fixed_version)
        dfs.append(extract_vulnerabilities(fixed_version, link))

    return pd.concat(dfs)


# if __name__ == 'main':
# scrape()
df = scrape()
df.to_csv('firefox.csv', sep='|', index=False, encoding='utf-8')
