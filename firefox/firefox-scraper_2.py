"""
Scrape Firefox vulnerability list from version 48 downward

each vulnerability contains:
+ title
+ reporter
+ impact
+ description
+ bug id and href

"""

import requests
from bs4 import BeautifulSoup
import re
import pandas as pd


def extract_vulnerabilities(version, url):
    """
    Extract vulnerability reported for a Firefox version

    :param version: Firefox version to be scraped
    :param url: firefox vulnerability link for specific version
    :return: a DataFrame containing all vulnerability information for the given Firefox version
    """

    cve_ids = []
    titles = []
    reporters = []
    impacts = []
    descriptions = []
    bug_ids = []
    try:
        r = requests.get(url)
        soup = BeautifulSoup(r.content, 'lxml')
        # extract heading
        content = soup.find(id="main-content")
        title = content.find("h2").text

        # extract summary
        summary = content.find(class_='summary')
        dds = summary.find_all('dd')
        reporter = dds[1].text
        impact = dds[2].find("span").text
        description = summary.find_next_sibling('p').text
        # summary.next

        references = summary.find_next_sibling("ul").find_all("a")

        bug_id = references[0]['href'].replace("https://bugzilla.mozilla.org/show_bug.cgi?id=", "")
        # ignore multiple bug ids for a vulnerability
        multibugs = "https://bugzilla.mozilla.org/buglist.cgi?bug_id="
        if multibugs in bug_id:
            bug_id = bug_id.replace(multibugs, "").split(",")

        cve_id = references[1].text

        # add extracted information to list
        cve_ids.append(cve_id)
        titles.append(title)
        reporters.append(reporter)
        impacts.append(impact)
        descriptions.append(description.replace(",", ""))
        if type(bug_id) is list:
            bug_ids = bug_id
        else:
            bug_ids.append(bug_id)

        df = pd.DataFrame({
            'version': [version] * len(bug_ids),
            'cve_id': cve_ids * len(bug_ids),
            'title': titles * len(bug_ids),
            'reporter': reporters * len(bug_ids),
            'impact': impacts * len(bug_ids),
            'description': descriptions * len(bug_ids),
            'bug_id': bug_ids,
        })
        return df

    except Exception:
        print("Error")
        return None


def scrape():
    firefox_vul_url = 'https://www.mozilla.org/en-US/security/known-vulnerabilities/firefox/'

    r = requests.get(firefox_vul_url)

    if r.status_code != 200:
        print('Can\'t retrieve the url %s' % firefox_vul_url)
        exit(1)

    soup = BeautifulSoup(r.content, 'lxml')

    versions = soup.find_all('h3', id=re.compile('^firefox'))[-66:]

    print(len(versions))

    dfs = []
    for v in versions:
        item = v.find_next_sibling('ul')
        vunerabilities = item.find_all("li")
        for vul in vunerabilities:
            class_item = vul.find('a')
            link = 'https://www.mozilla.org' + class_item['href']
            print(link)
            fixed_version = class_item['data'].replace('version', '').replace('"', '').replace('=', '')
            print(fixed_version)
            d = extract_vulnerabilities(fixed_version, link)
            if d is not None:
                dfs.append(d)

    return pd.concat(dfs)


# if __name__ == 'main':
# scrape()
df = scrape()
df.to_csv('data\\firefox_2.csv', index=False, encoding='utf-8')
