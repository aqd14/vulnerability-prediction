"""
Scrape data from https://www.cvedetails.com to create mapping between CVE ID and CWE ID
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd

# cve details for Firefox
URL = 'https://www.cvedetails.com/vulnerability-list/vendor_id-452/product_id-3264/Mozilla-Firefox.html'

# page prefix, used to form page links
PAGE_PREFIX = 'https://www.cvedetails.com'

r = requests.get(URL)

if r.status_code != 200:
    print('Can\'t retrieve the url %s' % URL)
    exit(1)


# data containers
nums = []
cve_ids = []
cwe_ids = []
num_exploits = []
vulnerability_types = []
publish_dates = []
update_dates = []
scores = []
gained_access_levels = []
accesses = []
complexities = []
authentications = []
confidentiality = []
integrity = []
availability = []


data = [
    nums, cve_ids, cwe_ids, num_exploits, vulnerability_types,
    publish_dates, update_dates, scores, gained_access_levels,
    accesses, complexities, authentications, confidentiality,
    integrity, availability
]

soup = BeautifulSoup(r.content, 'lxml')

pages = soup.find('div', id='pagingb').find_all('a')

for page in pages:
    link = PAGE_PREFIX + page['href']

    p = BeautifulSoup(requests.get(link).content, 'lxml')
    table = p.find(id='vulnslisttable')

    # get all table rows
    trs = table.find_all(class_='srrowns')
    for tr in trs:
        tds = tr.find_all('td')

        for i, td in enumerate(tds):
            t = td.text.replace('\n', '').replace('\t', '').strip()
            data[i].append(None if len(t) == 0 or t == 'None' else t)

df = pd.DataFrame({
    'num': nums,
    'cve_id': cve_ids,
    'cwe_id': cwe_ids,
    'num_exploit': num_exploits,
    'vul_type': vulnerability_types,
    'publish_date': publish_dates,
    'update_date': update_dates,
    'score': scores,
    'gained_access_level': gained_access_levels,
    'access': accesses,
    'complexity': complexities,
    'auth': authentications,
    'confidentiality': confidentiality,
    'integrity': integrity,
    'availability': availability
})

df.to_csv('firefox_vuls_mapping.csv', sep='|', index=False, encoding='utf-8')

