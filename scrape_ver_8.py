'''
Scrape Tomcat version 8 requirements and vulnerabilities
'''

import re
from contextlib import closing

import pandas as pd
import requests
from bs4 import BeautifulSoup
from requests.exceptions import RequestException


class HTMLTableParser:

    def simple_get(self, url):
        """
        Attempts to get the content at `url` by making an HTTP GET request.
        If the content-type of response is some kind of HTML/XML, return the
        text content, otherwise return None.
        """
        try:
            with closing(requests.get(url, stream=True)) as resp:
                if self.is_good_response(resp):
                    return resp.content
                else:
                    return None

        except RequestException as e:
            self.log_error('Error during requests to {0} : {1}'.format(url, str(e)))
            return None

    def is_good_response(self, resp):
        """
        Returns True if the response seems to be HTML, False otherwise.
        """
        content_type = resp.headers['Content-Type'].lower()
        return (resp.status_code == 200
                and content_type is not None
                and content_type.find('html') > -1)

    def log_error(self, e):
        """
        It is always a good idea to log errors.
        This function just prints them, but you can
        make it do anything.
        """
        print(e)

    # def extract_change_type(self, src):
    #     if 'fix' in src:
    #         return 'fix'
    #     elif 'update' in src:
    #         return 'update'
    #     elif 'add' in src:
    #         return 'add'
    #     else:
    #         return 'NaN'

    def parse_url(self, url):
        response = self.simple_get(url)
        soup = BeautifulSoup(response, 'lxml')
        # return [(table['id'], self.parse_html_table(table))
        #         for table in soup.find_all('table')]

        # each Tomcat version has its own table for showing change logs
        content = soup.find(id='content')
        versions = content.find_all('h3', {'id':re.compile('^Tomcat_8.0')}, recursive=False)
        change_logs = content.find_all('div', class_='text', recursive=False)
        dfs = []
        for version, change in zip(versions, change_logs):
            dfs.append(self.parse_html_table(version, change))

        return pd.concat(dfs)

    def parse_html_table(self, v, c):
        """
        Parse a HTML table
        :param table: html table to be parsed
        :return: a DataFrame containing all information about the changes
        """

        # columns = ['component', 'type', 'change', 'link']
        components = []
        # versions = []
        types = []
        changes = []
        links = []
        bug_ids = []

        p = re.compile('^[0-9]+:')

        # df = pd.DataFrame(columns=columns, index=range(0, n_rows))
        version = v.text

        change_tables = c.find_all('div', class_='subsection', recursive=False)  # each table shows changes for each component

        # inner_tables[0].text
        for ct in change_tables:
            component = ct.find('h4').text
            # print(component)

            # actual changes description
            try:
                change_lists = ct.find('ul', class_='changelog').find_all('li')
            except AttributeError as e:
                self.log_error(e)
                continue
            for cl in change_lists:
                components.append(component)
                change_type = cl.find('img')['alt']
                types.append(change_type[0:change_type.find(':')]) # remove unnecesary content
                # print(change_type)

                # extract hyperlink to the issue
                link = None
                if cl.find('a'):
                    link = cl.find('a')['href']
                    # print(link)
                # if link != 'NaN'
                links.append(link)
                whole_change = re.sub(' +', ' ', cl.text).strip().replace('\n', '')
                if p.match(whole_change):
                    change = whole_change.split(None, 1)[1]
                    id = whole_change.split(None, 1)[0].replace(':', '')
                else:
                    change = whole_change
                    id = None
                # print(change)
                bug_ids.append(id)
                changes.append(change)

        df = pd.DataFrame({
                'component': components,
                'version': [version] * len(changes),
                'type': types,
                'bug_id': bug_ids,
                'change': changes,
                'link': links
        })
        return df


parser = HTMLTableParser()
df = parser.parse_url('https://tomcat.apache.org/tomcat-8.0-doc/changelog.html')
df.to_csv('tomcat_v8.csv', sep='|', index=False, encoding='utf-8')
